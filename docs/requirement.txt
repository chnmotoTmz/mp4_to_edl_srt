create : Generate a Python script that does the following: Takes a folder path as input, containing MP4 files. For each MP4 file in the folder: a. Extracts the audio using FFmpeg. b. Uses Open AI's Whisper to transcribe the audio and get word-level time stamps. c. Groups the words into segments based on a silence threshold of 0.5 seconds between words. d. For each segment, records the start and end time codes in the original MP4 file. Generates a CMX 3600 EDL file with: Title: 'My Video Project' FCM: 'NON-DROP FRAME' Each event corresponding to a segment, with: Event number: incremental starting from 001 Reel name: 'TAPE' followed by a two-digit number (e.g., TAPE01 for the first file, based on file order) Track type: 'AA/V' (assuming both audio and video are present) Transition: 'C' for cut Source time codes: start and end time codes of the segment in the original MP4 file (HH:MM:SS:FF format, 30fps non-drop frame) Record time codes: sequential in the timeline, starting from 00:00:00:00, with each subsequent segment starting where the previous ends Comment: '* FROM CLIP NAME: filename.mp4' Generates an SRT file for all segments across all MP4 files, containing: Index: incremental starting from 1 Time codes: start --> end in HH:MM:SS,MMM format Transcription: the text from Whisper for that segment Assumptions: The frame rate is 30 fps non-drop frame. The time codes are in HH:MM:SS:FF format for EDL and HH:MM:SS,MMM for SRT. Dependencies: Open AI's Whisper API, FFmpeg for audio extraction, Python libraries for handling time codes and file operations. The script should be well-documented and include error handling for cases like missing files or API errors.