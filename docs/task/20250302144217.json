{"Required Python packages":["ffmpeg-python","whisper","pydub","opencv-python","pyyaml"],"Required Other language third-party packages":["No third-party dependencies required"],"Refined Logic Analysis":[["main.py","Orchestrates the overall process. Reads configuration from `config.json`. Creates `TimecodeConverter` and `SceneAnalyzer` instances. Iterates through input MP4 files, creating an `MP4FileProcessor` for each and calling its `process` method. Handles error handling and logging at the top level."],["mp4_file_processor.py","Contains the `MP4FileProcessor` class. Manages the processing pipeline for a single MP4 file: audio extraction (using FFmpeg via `subprocess`), frame extraction (using FFmpeg/OpenCV), transcription (using `whisper`), scene detection (delegating to `SceneAnalyzer`), audio segmentation (silence-based using `pydub`), assigning scene information to segments, generating `EDLData` and `SRTData` objects, and writing output files. Uses `TimecodeConverter` for timecode handling. Includes robust error handling."],["segment.py","Contains the `Segment` class. Represents a transcribed audio segment with start/end times (ms), transcription text, and associated scene ID/description. Provides methods to format timecodes for SRT output using `TimecodeConverter`."],["scene.py","Contains the `Scene` class. Represents a detected video scene with start/end times (ms), a unique scene ID, and a descriptive label. Provides methods to format timecodes for EDL output using `TimecodeConverter`."],["scene_analysis.py","Contains the `SceneAnalyzer` class. Handles loading the scene classification model. Uses OpenCV to extract frames from the video file, potentially at a configurable rate. Analyzes frames to identify scene boundaries based on classification changes and classify scenes, returning a list of `Scene` objects. Includes error handling for model loading and classification. Reports progress via a callback."],["timecode_utils.py","Contains the `TimecodeConverter` class. Provides methods to convert time representations: milliseconds to HH:MM:SS:FF (30fps non-drop frame), milliseconds to HH:MM:SS,MMM, HH:MM:SS:FF to milliseconds, and HH:MM:SS,MMM to milliseconds, based on a given frame rate (defaulting to 30fps for EDL)."],["edl_data.py","Contains the `EDLData` class. Structures the data required for an EDL file (title, FCM, list of events). Provides a method to add event data, incorporating scene information as comment lines (`* COMMENT`). Includes a method to format the data into an EDL string using `TimecodeConverter`."],["srt_data.py","Contains the `SRTData` class. Structures the data required for an SRT file (list of segments). Provides a method to add segment data, including transcription and scene information embedded within the text block of each segment. Includes a method to format the data into an SRT string using `TimecodeConverter`."],["config.json","Configuration file in JSON format. Specifies input/output folders, parameters for scene analysis (enable/disable, model details TBD, frame analysis rate), silence detection thresholds, and other configurable options."]],"Refined Task list":["timecode_utils.py","segment.py","scene.py","edl_data.py","srt_data.py","scene_analysis.py","mp4_file_processor.py","main.py","config.json"],"Full API spec":"","Refined Shared Knowledge":"The core processing logic for each file is encapsulated in the `MP4FileProcessor` class. Timecode conversions are handled by the `TimecodeConverter` in `timecode_utils.py`, specifically supporting 30fps non-drop frame for EDL. Scene detection is managed by the `SceneAnalyzer` in `scene_analysis.py`, which uses OpenCV for frame extraction (potentially at a configurable rate) and a pre-trained model for classification. Data structures for segments and scenes are provided by the `Segment` and `Scene` classes. Output formatting for EDL and SRT is handled by `EDLData` and `SRTData` classes, which will embed scene metadata: EDL using comment lines (`* COMMENT Scene ID: X, Description: Y`) and SRT by including scene info within the segment text block (e.g., `[Scene ID: X, Description: Y]\\nTranscription text...`). Configuration is read from `config.json`. Robust error handling using `try...except` blocks and logging using Python's `logging` module are essential throughout the application. FFmpeg is used via `subprocess` for audio extraction and potentially frame extraction. Transcription uses the `whisper` library. Segmentation is primarily silence-based using `pydub`, with scene information added as metadata to the resulting segments based on timecode overlap.","Anything UNCLEAR":"The exact format for embedding scene information in EDL and SRT files is proposed but needs final standardization/confirmation. The level of detail and type of description for scene information depends heavily on the chosen image classification model. Specific pre-trained models suitable for general scene classification in diverse video content, their licensing, and download mechanisms are still TBD and require further research. Balancing analysis speed and accuracy, especially for long videos or rapid scene changes, is a practical challenge; this is being addressed by making the frame analysis rate configurable (e.g., analyzing every Nth frame)."}